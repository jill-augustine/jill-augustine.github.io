[
["index.html", "Home Latest Projects About Me My Data Science Toolbox", " Home Welcome to my blog! This is where I share excerpts of my portfolio as well as professional resources I am currently using. I will also share some blog posts about experiences from my working life. Latest Projects Building a Data Exploration Web App with Shiny About Me Jillian Augustine, PhD. I am a data scientist and question answerer. I received my PhD in Molecular Biology from the University of Vienna (Austria) and my BSc from the University of Leeds (UK) during which I also studied at McGill University (Montreal, Canada). My main interest (and the reason I became a data scientist) is using data to answer questions regardless of the industry. I have experience working in the telecommunications industries. In particular I am passionate about data understanding and communication both to stakeholders and within data teams. My professional approach to data science is to use the tool that gets the job done given any constraints from team members and stakeholders. Another interest of mine is increasing the inclusivity of working groups through open exchanges and active diversificartion. I try to make my presentations are accessible as possible and welcome feedback as to how I can improve this further. I welcome opportunities to speak about my work at conferences and meetups. Please get in touch through Twitter or LinkedIn if you would like to know more. My Data Science Toolbox Here is a list of my current go-to tools. Data Manipulation: python Apache Spark R any combination of the above Microsoft Excel (for team members accustomed to pivot tables) (Real-Time) Data Collection/Extraction: SQL (Hive) Apache Kafka Data Storage: parquet files whenever possible Hadoop Distributed File System (HDFS) Linux computer clusters Data Visualisation: ggplot2 Machine Learning: caret (scikit-learn) Documentation/Project Work: R Markdown Confluence Jira Git "],
["data-exploration-with-shiny.html", "Data Exploration with Shiny What Who Where When Why How", " Data Exploration with Shiny If what you read below interests you, download the repository here which includes the code used to create the app as well as sample datasets. What Figure 1: Data can be loaded by providing a dataset ID number and a date range. This is a web application built with Shiny and R and designed to aid exploration of large datasets. With the example data provided you can view the music streaming habits of two users. Data for the two users is provided with the dataset IDs ‘eg01’ and ‘eg02’. Using the app you can see in which months they listened to which genres of music. You can also dive down to the individual months and days for more detail. Figure 2: Visualising customer data per day in graphical and tabular form. Behind the web app is a data pipeline which, upon pressing a button in the app, starts a Spark job. In this job, a script generates and runs SQL queries on a database. It then saves the results of the queries as parquets, and merges and repartitions the parquets to optimise performance. After checking for errors, it automatically sends emails a unique dataset ID to the person who requested the data. Using this ID the user can reenter the app to view the data. Finally the cleans up the disk space removing any temporary files created. The app also contains logging functionality. Everytime data is requested or viewed using the app, a record is added to the relevant log (logs_req.txt and logs_read.txt). This way, activity of the app can be tracked. Don’t forget, while most of the files in the app can be read only, users of the app must have permission to write to this file. Who This web application is designed for anyone who wants to have a summarised look at large amounts of data with the help of classic data visualisations. This app is also useful for users who prefer to work with spreadsheets because the raw data are also exportable as a ;-delimited file. Figure 3: Checkboxes are used to select which columns of data to load. This data can then be exported for use, for example, in Microsoft Excel. Where I’m interpretting the question as “where can I run this app”? If you clone the github repository you will also have a copy of the two example datasets. You can then run the app on your local machine from RStduio using the command shiny::runApp(\"path_to_dataEx_app_split_folder\", launch.browser = TRUE). The app was designed to be connected to a hadoop distributed file system (HDFS) and spark session. When Intepretting this question as something to do with time, this app took me 4 months working on and off. I initially made a prototype which looked quite different. I then asked for and incorporated feedback which resulted in the app in it’s current form. It was my first Shiny Web Application and I am very happy with the functionality of it. Why We often collect very large amounts of data that cannot be understood simply by looking at them. It helps to summarise theme data in the form of visualisations. Moreover, in cases where we have many customers or some other kind of category, it helps to be able to create individual reports. Why interactive? Too much data can be overwhelming. It’s much better to allow the end users to decide exactly what they want to visualise/export. How I chose Shiny to build this app because it seemed realtively simple to start to use (compared to other app making tools). I found the documentation and tutorials about Shiny very clear. Furthermore, I liked the range of themes to select from which meant I did not have to personalise all aspects of the user interface. "],
["useful-links.html", "Useful Links Documentation Books Social Podcasts Cheatsheets", " Useful Links I am often asked about which resources I use to improve and maintain my data science skills. Here is a list of websites I often use and would recommend. Documentation Whenever I am coding I have mutliple documentation pages open. It’s not possible to remember how every single function is used. Also clicking through the “related functions” lets me disocver new functions which are sometimes even more suited to what I want to do. RDocumentation The content of the help section of RStudio but a much better use interface. Allows you to have multiple tabs open relating to different functions/packages. pandas Documentation This documentation is best viewed using the search function. pyspark Documentation Although the search function is not the best, this is also essential whenever manipulating datasets using spark. caret Documentation In particular sections 6 and 7 list the available models. Sections 3, 4 &amp; 5 also describe some key principles of machine learning and how you can implement them using caret. Regular Expressions (regex) Tester A great tool to check if a pattern successfully recognises characters in a given input. Helps to understand unexpected outputs of code. colorbrewer2 A colour-selection tool developed by Prof. Cynthia Brewer. I use this tool to select the best colours for my visualisations. I particularly like the “colorblind safe” option. This tool works great in combination with some of the principles of O. Wilke’s book (see below) R Graphics Cookbook This book by Winston Chang should be your first reference when trying to work out how to do certain things using ggplot2. w3schools I use this to brush up on my SQL and HTML knowledge. The instructions are clear and the site is easy to navigate. stackoverflow This is a question and answer site about a range of coding topics. It’s not a site I would ever go on to search for specific questions. But when I google something and see one of the results is a page in stackoverflow there is a good chance it will help my answer my question. Shiny Tutotials (RStudio) A collection of video and written tutorials great for helping you develop shiny web applications. Books Python Data Science Handbook I’ve not read it yet myself. I heard it is a very comprehensive resource for data science in python. Weapons of Math Destruction - Cathy O’Neil Because we are not doing data science in an isolated bubble. Our decisions have consequenses and this book is a great start to being aware of them. Fundamentals of Data Visualization - Claus O. Wilke I’ve not fully explored this yet but it seems like a great resource on how to ensure your data visualisations are as communicative as possible and tell the story you want to tell. Social Twitter I like to stay active in the twitter-sphere to keep track of the latest data science goings-on. You can hear directly from any data scientists/programmers/visualisation experts you admire. Recommended hashtags to search for/accounts to follow: #rstats #WomenInTech @rstudio @vboykis (Vicky Boykis) @csdoctorsister (Dr Brandeis Marshall) I’m looking for more python related tweeters. Please let me know if you find any. Vienna Data Science Group (vdsg) I recently attended a hackathon run by VDSG in which I worked on projects from non-profit organisations to help them get the most out of their data. R-Ladies Vienna Events ranging from beginner to advanced on different R topics. Women&amp;&amp;Code I’ve not been to this series of meetups but I’ve heard great things about it. Podcasts Data Stories All things data visualisation Linear Digressions This podcast is an intermediate level podcast about different machine learning related mathmatical concepts and algorithms. Presented by one expert, Katie Malone, and one non-expert, Ben (couldn’t find his SM details!). Freakonomics Radio If you’re curious about the role of data in the real world, this podcast is for you. Cheatsheets R Cheatsheets A great collection of around 30 cheatsheets for different tidyverse and non-tidyverse packages in R. Scikit-learn An overview of the key functions to use when doing machine learning in python usinf scikit-learn. pandas Cheatsheet Complementary to the pandas documentation. This gives an overview of commonly used functions. "]
]
